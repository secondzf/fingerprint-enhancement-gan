import os
import torch
from torchvision.utils import save_image
from config import Config

def save_samples(inputs, outputs, targets, save_dir, epoch, stage_idx, max_samples=4):
    """
    ä¿å­˜è®­ç»ƒæ ·æœ¬ä¸ºæ‹¼æ¥å›¾ç‰‡: è¾“å…¥(é€€åŒ–å›¾) + ç”Ÿæˆ(ä¿®å¤å›¾) + æ ‡ç­¾(æ¸…æ™°å›¾)
    :param stage_idx: 1, 2, 3 æˆ– 'aftrain'
    :param max_samples: æ¯ä¸ª epoch æœ€å¤šä¿å­˜çš„æ ·æœ¬æ•°ï¼Œé˜²æ­¢ç£ç›˜æº¢å‡º
    """
    os.makedirs(save_dir, exist_ok=True)

    # ç¡®å®šä¿å­˜æ•°é‡ï¼Œä¸å¤§äºå½“å‰ batch ä¹Ÿä¸å¤§äºæœ€å¤§é™åˆ¶
    num_to_save = min(len(inputs), max_samples)

    for i in range(num_to_save):
        # ç»Ÿä¸€å¤„ç†å½’ä¸€åŒ–èŒƒå›´ï¼šä» [-1, 1] æ˜ å°„åˆ° [0, 1]
        def to_img(t):
            t = t.detach().cpu()
            if t.min() < 0:
                t = t * 0.5 + 0.5
            return torch.clamp(t, 0, 1)

        inp = to_img(inputs[i])
        out = to_img(outputs[i])
        tgt = to_img(targets[i])

        # æ¨ªå‘æ‹¼æ¥: [C, H, W*3]
        concat = torch.cat([inp, out, tgt], dim=2)
        
        # å‘½åæ ¼å¼ï¼šstage_X_epoch_X_idx_X.png
        file_name = f'stage_{stage_idx}_epoch_{epoch:03d}_sample_{i}.png'
        save_path = os.path.join(save_dir, file_name)
        
        save_image(concat, save_path)

def save_model(model, save_dir, stage_idx, epoch, is_best=False):
    """
    ä¿å­˜æ¨¡å‹æƒé‡
    :param is_best: å¦‚æœä¸º Trueï¼Œé¢å¤–ä¿å­˜ä¸€ä»½åä¸º best çš„æƒé‡
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # åŸºç¡€æ–‡ä»¶å
    model_name = f'generator_stage_{stage_idx}_epoch_{epoch:03d}.pth'
    save_path = os.path.join(save_dir, model_name)
    
    # ä¿å­˜å½“å‰æƒé‡
    torch.save(model.state_dict(), save_path)
    
    # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œå¤åˆ¶ä¸€ä»½
    if is_best:
        best_path = os.path.join(save_dir, f'generator_stage_{stage_idx}_best.pth')
        torch.save(model.state_dict(), best_path)
        print(f"â­ å·²æ›´æ–°é˜¶æ®µ {stage_idx} çš„æœ€ä½³æ¨¡å‹æƒé‡")

def load_checkpoint(model, path):
    """
    è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ–­ç‚¹/é¢„è®­ç»ƒæƒé‡
    """
    if os.path.exists(path):
        state_dict = torch.load(path, map_location=Config.device)
        model.load_state_dict(state_dict, strict=False)
        print(f"ğŸ“– æˆåŠŸä» {path} åŠ è½½æƒé‡")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°è·¯å¾„: {path}ï¼Œè·³è¿‡åŠ è½½")
    return model